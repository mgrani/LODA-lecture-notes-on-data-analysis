{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Course: Web Mining Project (5944P)\n",
    "\n",
    "Master of Computer Science@University of Passau\n",
    "\n",
    "by \n",
    "\n",
    "[__Michael Granitzer__ (michael.granitzer@uni-passau.de)]( http://www.mendeley.com/profiles/michael-granitzer/)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "__License__\n",
    "\n",
    "This work is licensed under a [Creative Commons Attribution 3.0 Unported License](http://creativecommons.org/licenses/by/3.0/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "internals": {
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "console.log(\"Section numbering...\");\n",
       "\n",
       "function number_sections(threshold) {\n",
       "\n",
       "  var h1_number = 0;\n",
       "  var h2_number = 0;\n",
       "\n",
       "  if (threshold === undefined) {\n",
       "    threshold = 2;  // does nothing so far\n",
       "  }\n",
       "\n",
       "  var cells = IPython.notebook.get_cells();\n",
       "  \n",
       "  for (var i=0; i < cells.length; i++) {\n",
       "\n",
       "    var cell = cells[i];\n",
       "    if (cell.cell_type !== 'heading') continue;\n",
       "    \n",
       "    var level = cell.level;\n",
       "    if (level > threshold) continue;\n",
       "    \n",
       "    if (level === 1) {\n",
       "        \n",
       "        h1_number ++;\n",
       "        var h1_element = cell.element.find('h1');\n",
       "        var h1_html = h1_element.html();\n",
       "        \n",
       "        console.log(\"h1_html: \" + h1_html);\n",
       "\n",
       "        var patt = /^[0-9]+\\.\\s(.*)/;   // section number at start of string\n",
       "        var title = h1_html.match(patt);  // just the title\n",
       "\n",
       "        if (title != null) {  \n",
       "          h1_element.html(h1_number + \". \" + title[1]);\n",
       "        }\n",
       "        else {\n",
       "          h1_element.html(h1_number + \". \" + h1_html);\n",
       "        }\n",
       "        \n",
       "        h2_number = 0;\n",
       "        \n",
       "    }\n",
       "    \n",
       "    if (level === 2) {\n",
       "    \n",
       "        h2_number ++;\n",
       "        \n",
       "        var h2_element = cell.element.find('h2');\n",
       "        var h2_html = h2_element.html();\n",
       "\n",
       "        console.log(\"h2_html: \" + h2_html);\n",
       "\n",
       "        \n",
       "        var patt = /^[0-9]+\\.[0-9]+\\.\\s/;\n",
       "        var result = h2_html.match(patt);\n",
       "\n",
       "        if (result != null) {\n",
       "          h2_html = h2_html.replace(result, \"\");\n",
       "        }\n",
       "\n",
       "        h2_element.html(h1_number + \".\" + h2_number + \". \" + h2_html);\n",
       "        \n",
       "    }\n",
       "    \n",
       "  }\n",
       "  \n",
       "}\n",
       "\n",
       "number_sections();\n",
       "\n",
       "// $([IPython.evnts]).on('create.Cell', number_sections);\n",
       "\n",
       "$([IPython.events]).on('selected_cell_type_changed.Notebook', number_sections);\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#some configuration stuff to be ignored\n",
    "#loads section numbering https://github.com/ipython/ipython/wiki/Extensions-Index\n",
    "%reload_ext secnum\n",
    "%secnum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation - the Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_number": 3
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The Web has become the largest source of information in the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 4,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"files/images/web-data-infographic.jpeg\"/>\n",
    "Source: http://royalonlinemedia.wordpress.com/2013/02/28/new-journalism-data-infographics/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 4,
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Some Questions**\n",
    "- But what can we learn from this data?\n",
    "- What kind of services can we build around it?\n",
    "- What insights and knowledge is hidden in the pattern?\n",
    "- Does the data tell us something on our own behaviour?\n",
    "- Does it allow to answer sociological/psychological questions?\n",
    "- ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 4,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What is Web Mining?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 7
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class =\"alert alert-sucess\">\n",
    "**Web mining** is the use of data mining techniques  to automatically discover and extract information from Web documents/services (Etzioni, 1996)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 8,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Web Content Mining:** Extract knowledge out of documents and user content in the web (e.g. Filtering messages in social networks)\n",
    "- **Web Structure Mining:** Analyse the graph structure of the web and identify interesting patterns (e.g. Page Rank)\n",
    "- **Web Usage Mining:** Analyse the usage of web systems and extract interesting patterns (e.g. Analyse Navigation Paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 8,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1.2. Google Flu Trends - an Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 10
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "[Google Flu Trends](http://www.google.org/flutrends/de/#DE) - Can we predict flu outbreaks from search behaviour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 11,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"files/images/flu-trends.png\"\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 11,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Fields of Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 13,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Web Search \n",
    "- Personalisation in E-Commerce (e.g. Amazon)\n",
    "- Recommender Systems\n",
    "- Advertisement/Tracking User Behaviour\n",
    "- Digital Libraries\n",
    "- Web Site Optimization\n",
    "- Social Media Analytics (e.g. for Marketing)\n",
    "- Sociology Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 13,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A small Use Case Example - Personal Filtering of Twitter Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 13,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "[Twitter](http://Twitter.com) - a social network for short messages\n",
    "<img src=\"files/images/twitter example.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 13,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's consider a small use case: lets say we need a program that filters Twitter Messages (Tweets) according to our interest. The program should conduct the following functions:\n",
    "\n",
    "1. Tweets should be crawled from Twitter\n",
    "2. A user somehow must express what is relevant and what is not relevant for them\n",
    "3. Our program needs to represent this notion of relevance somehow\n",
    "4. Our program should store the relevant tweets in the users inbox/pc\n",
    "5. Our program should allow the user to give feedback on what tweet is relevant/not relevant and adapt its strategy\n",
    "5. Our program should group relevant tweets together according to their topic\n",
    "6. Our program should show us the development of a topic over time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 17,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"aler alert-info\">\n",
    "How would you solve this problem?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 17,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sketching the Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 19
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "### Step 1 - Data Gathering\n",
    "\n",
    "Crawling/Gathering Data from Twitter. In case of Twitter it is easy, since they provide an [API](https://dev.twitter.com/).\n",
    "\n",
    "Crawling abritrary web pages requires to write more complicated crawlers and consider different formats. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 20,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "### Step 2 - Machine Learning - Classification \n",
    "\n",
    "By using Machine Learning methods, we can automatically classify tweets belonging to a certain class. So called **Supervised Learning Methods** learn rules (e.g. mathematical models)from those examples to classify future, yet unkown examples.\n",
    "\n",
    "So a user would mark tweets as relevant/non-relevant. The tweets are then used to estimate a model to predict future tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 20,
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Step 3 - Machine Learning - Clustering \n",
    "\n",
    "Clustering belongs to the **Unsupverised Machine Learning** methods. They group similar items toghether while maintaining maximal dissimilarity between groups.\n",
    "\n",
    "Using clustering allows us to group tweets which are similar together, while the groups itself are most dissimlar. So tweets from two different groups do not have a lot in common. This seems to be a reasonable approximation for our topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 20,
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### Step 4 - Visualising Data\n",
    "\n",
    "After obtaining topics in form of groups of similar tweets, we need to display the number of tweets per topic over the time. Could look like:\n",
    "\n",
    "<img src=\"files/images/10SteamGraph2.jpg\"/>\n",
    "\n",
    "Source: [Twitter StreamGraph](http://www.neoformix.com/Projects/TwitterStreamGraphs/view.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 20,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Digging Deeper - How to do the heavy lifting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 24,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Machine Learning** is the core of our application. So how could this work? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 24,
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### A Linear Model for Classifying Tweets\n",
    "\n",
    "Lets assume relevance of a tweet only depends on the word occuring in a tweet. So a model for classifying tweets could be simply to \n",
    "\n",
    "1. Assign every word a with how relevant it is\n",
    "2. Sum up all the relevance for every word in a tweet\n",
    "3. If the sum exceeds a certain threshold, i.e. there are a lot of relevant words in a tweet, the whole tweet must be relevant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 24,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "####  More formally\n",
    "\n",
    "Let\n",
    "\n",
    "- $T$ be a list of tweets with denoting $t_j$ als j-th tweet\n",
    "- $D$ be the dictionary of all words in all tweets \n",
    "- $d_i\\in D$ be the i-th word in the dictionary\n",
    "- $w_i\\in W$ be the relevance of $d_i$. Let $w_i>0$ denotes positive relevance and let $w_i<0$ denotes negative relevance\n",
    "- $f_{i,j}$ denotes how often $d_i$ occures in $t_j$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 27
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then a tweet relevance score can be calculated as weighted sum of word occurences:\n",
    "\n",
    "$$\n",
    "relevance(t_j) = \\sum_{d_i\\in D} w_i*f_{i,j}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 28,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And we can classify a tweet as relevant when its relevance score exceeds a certain threshold:\n",
    "\n",
    "$$\n",
    "classify(t_j) = \\left\\{\n",
    "  \\begin{array}{lr}\n",
    "    0 & : relevance(t_j)-\\theta<0 \\\\\n",
    "    1 & : relevance(t_j)-\\theta>0 \\\\\n",
    "  \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 28,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Representing Tweets as Matrix\n",
    "\n",
    "For a more compact representation, we can represent each tweet as vector $\\overline{f_j}$ of word occurences and all tweets as matrix $F$. Hence, classifying becomes vector/matrix operations:\n",
    "\n",
    "$$\n",
    "F*\\overline{w}-\\theta>0\n",
    "$$\n",
    "\n",
    "with $\\overline{w}$ being the vector of relevance weights (note that strictly mathematically speaking $\\theta$ must be a vector. Most machine learning methods utilize such a matrix representation. Obtaining this matrix representation is called \"preprocessing\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 30,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "**As a consequence, for successfully applying web mining techniques we need to**<br>\n",
    "<ol>\n",
    "    <li> convert our data to matrices and vectors (**preprocess data**)\n",
    "    <li> apply matrix operations/linear algebra (**numerical computations**)\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 30,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### How to obtain the weights?\n",
    "\n",
    "Trying to set the weights manually can be a tedious at its best. For practical scenarios it can be considered to be impossible. So we would like to have some machinery to estimate the weights.\n",
    "\n",
    "In order to get such a machinery working, we need to have\n",
    "\n",
    "1. manually labelled data, i.e. Tweets, that are considered to be relevant and some non-relevants\n",
    "2. an algorithm to \"learn\" the weights based on the manually labelled data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 32,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<div class = \"alert alert-info\">\n",
    "How would you adjust the weights?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 32,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Observation:\n",
    "\n",
    "1. if $relevance(t_j)-\\theta>0$ &nbsp; but&nbsp; $t_j$&nbsp; is **not relevant** to the user, that means the relevance $w_i$ for all words $d_i$ in $t_j$ was to high and need to be reduced. \n",
    "2. if $relevance(t_j)-\\theta<0$&nbsp; but&nbsp; $t_j$&nbsp; is **relevant** to the user, that means the relevance $w_i$ for all words $d_i$ in $t_j$ was to low and need to be increased. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 34
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "So lets define $y_j$ as being 1 for a relevant tweet and 0 otherwise. Then we can define the error as \n",
    "$$\n",
    "error_{j} = classify(t_j)- y_j\n",
    "$$ \n",
    "\n",
    "and devise a simple update rule for tweet $t_j$ as:\n",
    "\n",
    "$$\n",
    "w_i = w_i - \\eta*error_{j}*f_{i,j}\n",
    "$$\n",
    "\n",
    "with $\\eta\\in[0,1]$ being a small constant called learning rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 35
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the update of a weight for a tweet looks like\n",
    "\n",
    "|$y_j$|$classify(t_j)$|new $w_i$|\n",
    "|----|----------------|---------|\n",
    "| 1  | 0              |increase |\n",
    "| 0  | 1              |decrease |\n",
    "| 0  | 0              |no update|\n",
    "| 1  | 1              |no update|\n",
    "\n",
    "Doing this for all tweets $t_j\\in T$ updates the weights correspondingly. You might need to do that during several iterations.\n",
    "\n",
    "There are numerous methods for solving this more efficently and more accurately. We will review some of those methods during this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 36,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<div class=\"alert alert-success\"> \n",
    "<ol>\n",
    " <li> The algorithm sketched here is called stochastic gradient descent and the model is a linear model. More details later on.\n",
    " <li> Every supervised learning algorithm needs feedback to adjust it's model accordingly. In nearly all cases these are single examples labeled with the target value. \n",
    " <li> Manually labelled data is in most settings the most scarce resource\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 36,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extracting topics - Clustering Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 36
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can distinguish between relevant and non-relevant tweets. But how to group the relevant tweets into single topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 39
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First we need to define what a topic is:\n",
    "\n",
    "We define a topic as a group of tweets **similar in content**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 40,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "So how would you determine the similarity between two tweets?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 40,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Calculating the similartiy between tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 42
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Observation:* Two tweets which are similar share similar words\n",
    "\n",
    "*Hypothesis:* The more words are shared, the higher the similarity between two tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 43
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Formally**\n",
    "\n",
    "Let $\\overline{f_j}$ be the word frequency vector for a tweet, then the similarity between two tweets $t_j$ and $t_i$ can be calculated as \n",
    "\n",
    "$$\n",
    " sim_{j,i}= \\overline{f_j}^T\\cdot\\overline{f_i}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 44
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to get a measure in the intervall $[0,1]$ we need to scale both vectors to unit length:\n",
    "\n",
    "$$\n",
    " sim_{j,i}= \\frac{\\overline{f_j}^T\\cdot\\overline{f_i}}{|\\overline{f_j}||\\overline{f_i}|}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 45,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<div class =\"alert alert-success\">\n",
    "This measure is also known as **cosine measure** between two vectors. It measures the cosine of the angle between two measuers and is widley used in web mining (more accurately for sparse vector spaces)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 45,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Clustering - Grouping similar tweets together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 45
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "We can now estimate the similarity of two tweets. But how to get groups of similar tweets and can a tweet be in more than one group?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 48
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to ease the task we make the followig assumption: *One tweet belongs to one group/topic*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 49,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-info\"> \n",
    "Given the similarity measure, how could you find groups of similar tweets?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 49,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Idea**\n",
    "\n",
    "1. Lets choose $k$ tweets which represent different topics as starting point. \n",
    "2. now calculate the similartiy between all tweets $t_j\\in T$ and all $k$ representative tweets\n",
    "3. Assign tweet $t_j$ to the topic with the highest similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 51
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "This is the first step in the well known **k-means Clustering Algorithm**. There are many more clustering algorithm and we will look into some of them (and their properties)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 52,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Do you know why Steps 1.-3. are not sufficient for finding a good grouping?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 52,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What I offer to you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 54,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We will not be able to cover all aspects of web mining. However, the **goal is to help you on your first steps to mine the web**. \n",
    "\n",
    "<p> Mining means to extract new, potentially interesting and valid patterns from web sources.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 54,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lecture Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 56,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are a lot of tools and technologies out there to do so. In this course, we will use the Python programming language and its tons of libraries. \n",
    "\n",
    "To give you the necessary abilities to mine the Web with Python, **I** will give lectures and practical exercises on the following topics:\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<ol>\n",
    "<li> A short introduction to Data Science with Python\n",
    "<li> An introduction to the Python Programming Language\n",
    "<li> Important libraries for Data Science (plus the minimum necessary underlying theory)\n",
    "    <ol>\n",
    "       <li>**Crawling Twitter** and **Cleaning HTML**\n",
    "       <li>**Preprocessing Text:** NLTK - Natural Language Toolkit \n",
    "       <li>**Numerical Computation:** Numpy - Efficient Numerical Computations       \n",
    "       <li>**Machine Learning:** Scikit Learn - A easy-to-use machine learning library \n",
    "       <li> **Visualisation:** Matplotlib\n",
    "    </ol>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "We will focus mostly on practical aspects. Theory (e.g. algorithmic details) is only covered where necessary. \n",
    "\n",
    "However, I recommend that you also start obtaining the theoretical background, especially in machine learning. Only with a deep theoretical understanding you will be able to truely master the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 56,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Your Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 58,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Experience is the best teacher. So in order to master the subject, you need to conduct a web mining project on predefined topics.\n",
    "\n",
    "### Project Topics\n",
    "\n",
    "Our main data source will be [Twitter](http://www.twitter.com), simply because it provides an easy to use data source. \n",
    "\n",
    "As a second data source, web pages in form of the [WebKB data set](http://www.cs.cmu.edu/~webkb/) will also be available. \n",
    "\n",
    "The following topics will be available\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<ul>\n",
    "<li> Automatic Shitstorm Detection in Twitter (Group of 2-3)\n",
    "<li> Reveal topic, event and person distributions in Twitter (Group of 2-3)\n",
    "<li> Sentiment analysis on Twitter Data (Group of 2)\n",
    "<li> Web page classification (Group of 1-2)\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "\n",
    "Every topic is associated with a set of questions, that should be answered by you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 58,
     "slide_helper": "subslide_end",
     "slide_type": "subslide"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How - Timeline and Grading   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 58,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 61,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- **October to December**: Building up the basics. Lectures by me supplemented with small exercises for you\n",
    "- **December 5th**: Group and topic assignment\n",
    "- **December to January**: Time to work on your project\n",
    "- **End of January**: Report your findings to your colleagues in a brief presentation (10 minutes)\n",
    "\n",
    "All details are provided in [Stud.IP](https://studip.uni-passau.de/studip/seminar_main.php?auswahl=0733c229176a53b95f2f54c856755da8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 61,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 63,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "subslide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "Grading is based solely on your project:\n",
    "1. How accurate can you solve the task at hand?\n",
    "2. How good do your results generalize?\n",
    "3. What are the most important properties of the data to solve your task at hand?\n",
    "4. What is the most suitable algorithm and why?\n",
    "5. How correct is your justification of all the above points?\n",
    "\n",
    "Since you can work in groups, you  must make clear how fullfilled which role. The following roles can be foreseen:\n",
    "\n",
    "- **Data Gathering and Preprocessing:** Fetch the data and bring it in a usable form\n",
    "- **Data Analysis Process:** Setup the data analysis process by selecting algorithms and methods\n",
    "- **Evaluation:** Setup the evaluation procedure.\n",
    "\n",
    "The single roles are interwined and depend on each other. \n",
    "\n",
    "All your results must be summarized in an IPython Notebook. I will have a talk with every group regarding the contents of the notebook (Abgabegespr√§ch) in order to determine quality and correctness of your results and to make sure the work has been done by you as claimed.\n",
    "\n",
    "\n",
    "The course counts as \"Wahlfach Alg+Math\" and as \"Wahlpflichtpfach InfKomm\" for the Master Informatik (StPO 2012)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": false,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 63,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 65,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "- **There is no mandatory attendance**: If you already know a particular topic or if you want to learn it on you own, you dont have to participate the weekly lecture. Note: You are learning for you, not for me.\n",
    "\n",
    "- **Teamwork yes, plagiarism no**: Team work and discussing problems is important. However, copying code is forebidden and counts as plagiarism. If i encounter plagiarism in a group, all members will be graded with 5. \n",
    "\n",
    "- **You must be able to explain your work to me**: If one member of a group can not explain to me what he/she did *in detail*, i consider the work has been done by somebody else and will grade it as 5.\n",
    "\n",
    "- **Asking questions is not forbidden**: Please, have the courage to ask questions if you are not understanding something. \n",
    "\n",
    "<p>\n",
    "<div class=\"alert alert-error\">\n",
    "**The most important rule:** Have fun digging into data\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 65,
     "slide_type": "subslide"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reading Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "internals": {
     "frag_helper": "fragment_end",
     "frag_number": 67,
     "slide_helper": "subslide_end"
    },
    "slide_helper": "slide_end",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "** All material presented in the lecture is available on GitHub**\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "[LODA - Lecture Notes on Data Analysis](https://github.com/mgrani/LODA-lecture-notes-on-data-analysis)\n",
    "</div>\n",
    "\n",
    "**Recommended Readings**\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "\n",
    "Machine Learning, T. Mitchell, McGraw Hill 1997 (http://www.cs.cmu.edu/~tom/mlbook.html)\n",
    "</div>\n",
    "<div class=\"alert alert-success\">\n",
    "Pang-Ning Tan, Michael Steinbach, Vipin Kumar, Introduction to Data Mining, 2006, Pearson Education\n",
    "</div>\n",
    "\n",
    "** Recommended Readings for a Short Introduction to Web Mining **\n",
    "\n",
    "- Raymond Kosala and Hendrik Blockeel. 2000. Web mining research: a survey. SIGKDD Explor. Newsl. 2, 1 (June 2000), 1-15. DOI=10.1145/360402.360406 http://doi.acm.org/10.1145/360402.360406\n",
    "\n",
    "\n",
    "Further, individual material will be presented within every lecture.\n",
    "\n",
    "You can also attend the Course \"Machine Learning and Data Mining\" or \"Text Mining\" for obtaining a deeper theoretical foundation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
